---
title: "Aprendizado Supervisionado"
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  out.width = "50%", out.height = "50%",
  fig.retina = 2
)
```

## Aprendizado Supervisionado

Suponha que você observou uma variável resposta $Y$ e $p$ diferentes variáveis 
explicativas $X_1, X_2, ..., X_p$. Assumimos que existe alguma relação entre $Y$
e $X = (X_1, X_2, ..., X_p)$. Podemos denotar matematicamente esta relação como
na seguinte equação:

$$Y = f(X) + \epsilon$$

O objetivo geral do aprendizado supervisionado é estimar a função $f$.
Nessa formulação, $\epsilon$ é um termo de erro aleatório com média 0. $f$ representa
a informação sistemática que $X$ fornece sobre $Y$.

Existem diversas maneiras de estimar essa função. Em alguns casos assumimos uma
forma paramétrica para ela, em outros não. Alguns exemplos de algoritmos são:

* Regressão Linear
* Regressão Logística
* Árvore de Decisão
* Florestas Aleatórias (*Random Forest*)
* Gradient Boosting
* Redes Neurais
* Etc.

Cada um dos algoritmos possui as suas vantagens e desvantagens, e problemas em 
que trazem melhores resultados ou não. 
